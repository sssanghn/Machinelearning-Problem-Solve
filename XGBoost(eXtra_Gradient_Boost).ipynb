{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpKIRA49Jd1H2+5KlXSln5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sssanghn/Machinelearning-Problem-Solve/blob/main/XGBoost(eXtra_Gradient_Boost).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBoost"
      ],
      "metadata": {
        "id": "23wEaCqgojH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost**\n",
        "\n",
        "> XGBoost는 트리 기반의 앙상블 학습에서 가장 각광받고 있는 알고리즘 중 하나이다. </br>\n",
        "분류에 있어서 일반적으로 다른 머신러닝보다 뛰어난 예측 성능을 나타낸다. </br>\n",
        "XGBoost는 GBM에 기반하고 있지만, GBM의 단점인 느린 수행 시간 및 과적합 규제(Regularization)\n",
        "부재 등의 문제를 해결했다. </br>\n",
        "특히 XGBoost는 병렬 CPU 환경에서 병렬 학습이 가능해 기존 GBM보다 빠르게 학습을 완료할 수 있다."
      ],
      "metadata": {
        "id": "upn9iDQ6nGK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**XGBoost의 주요 장점**\n",
        "* 뛰어난 예측 성능\n",
        "* GBM 대비 빠른 수행 시간\n",
        "* 과적합 규제(Regularization)\n",
        "* Tree pruning(나무 가지치기) => 더 이상 긍정 이득이 없는 분할을 가지치기해서 분할 수를 더 줄이는 추가적인 장점이 있다.\n",
        "* 자체 내장된 교차 검증 => 교차 검증을 통해 평가 데이터셋의 평가 값이 최적화되면 반복을 중간에 멈출 수 있는 조기 중단 기능이 있다.\n",
        "* 결손값 자체 처리\n",
        "\n",
        "> XGBoost 자체적으로 교차 검증, 성능 평가, 피처 중요도 등의 시각화 기능을 가지고 있다."
      ],
      "metadata": {
        "id": "sWNg3HVjnuss"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost는 GBM과 유사한 하이퍼 파라미터를 동일하게 가지고 있으며, 여기에 조기 중단, 과적합을 규제하기 위한 하이퍼 파라미터 등이 추가되었다. </br> </br>\n",
        "다음으로, 파이썬 래퍼 XGBoost와 사이킷런 래퍼 XGBoost의 하이퍼 파라미터가 어떻게 다른지 알아보자."
      ],
      "metadata": {
        "id": "CkCeCF0oo8J7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 파이썬 래퍼 XGBoost 하이퍼 파라미터"
      ],
      "metadata": {
        "id": "Vl4vAFQrod6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**파이썬 래퍼 XGBoost 적용 - 위스콘신 유방암 예측**"
      ],
      "metadata": {
        "id": "Q-BCCNiDqWRm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykXVOh72m0d7",
        "outputId": "7e1dc16a-aca0-481b-c8ba-a31210b8f24f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.3\n"
          ]
        }
      ],
      "source": [
        "import xgboost\n",
        "\n",
        "print(xgboost.__version__)"
      ]
    }
  ]
}